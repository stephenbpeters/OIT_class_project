{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a548bbfc-2e47-432d-bc30-a570957adc7a",
   "metadata": {},
   "source": [
    "# Graphs!\n",
    "### Let's see about making some graphs and charts\n",
    "Looking at our file with resource calculations, this prompt gives good suggestions:\n",
    "resources_by_hood_calc-csv.csv\n",
    "Each record in this file is a portland neighborhood.  number_of_locations is the count of homeless resource providers in that neighborhood.  final_resource_calc is the sum of all the resources available in that neighborhood, which is the rest of the fields except for the two I just described and the first one which is \"neighborhood\".   What interesting statistics, charts and graphs would you suggest for this data? \n",
    "\n",
    "But I think I first need to add homeless population counts by neighborhood.\n",
    "IRP_Campsite_Reports_latlong-hood-zips-2024.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bfea9e-002a-4fb4-8acf-7213c03c91e9",
   "metadata": {},
   "source": [
    "Before we do that, I think we should add a column to our original file for \"homeless_pop\" and calculate that by the count of the number of times each individual neighborhood appears in the attached file.  If a neighborhood appears in the second file, but not the first, a record should be created for it and the rest of the values in that row can be 0. I would like the python code for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41cd4358-2984-4669-a85f-1c60720b8142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n",
      "Saved with homeless_camps added: C:\\Users\\Steph\\local\\OIT-class\\project-files\\datasets\\processed\\resources_by_hood_with_homeless_camps-csv.csv\n",
      "              neighborhood  library_open  temporary_shelter  day_center  \\\n",
      "0                  Alameda             0                  0           0   \n",
      "1              Arbor Lodge             0                  0           0   \n",
      "2  Ardenwald-Johnson Creek             1                  0           1   \n",
      "3            Argay Terrace             0                  0           0   \n",
      "4        Arlington Heights             0                  0           0   \n",
      "\n",
      "   coord_reentry  group_therapy  showers  meals  food_box  laundry  \\\n",
      "0              0              0        0      0         0        0   \n",
      "1              0              0        0      0         0        0   \n",
      "2              0              0        1      0         1        0   \n",
      "3              0              0        0      0         0        0   \n",
      "4              0              0        0      0         0        0   \n",
      "\n",
      "   health_services  misc_services  number_of_locations  final_resource_calc  \\\n",
      "0                0              0                    0                    0   \n",
      "1                0              0                    0                    0   \n",
      "2                1              1                    1                    6   \n",
      "3                0              0                    0                    0   \n",
      "4                0              0                    0                    0   \n",
      "\n",
      "   homeless_camps  \n",
      "0               8  \n",
      "1             287  \n",
      "2             189  \n",
      "3             601  \n",
      "4              51  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "print(\"Libraries imported!\")\n",
    "\n",
    "# --- INPUT PATHS (edit as needed) ---\n",
    "orig_path = Path(\"C:/Users/Steph/local/OIT-class/project-files/datasets/processed/resources_by_hood_calc-csv.csv\")  # one row per neighborhood, resource columns\n",
    "irp_path  = Path(\"C:/Users/Steph/local/OIT-class/project-files/datasets/processed/IRP_Campsite_Reports_latlong-hood-zips-2024.csv\")  # many rows; we'll count by neighborhood\n",
    "out_path  = Path(\"C:/Users/Steph/local/OIT-class/project-files/datasets/processed/resources_by_hood_with_homeless_camps-csv.csv\")\n",
    "\n",
    "# --- Helpers ---\n",
    "def normalize_hood(series: pd.Series) -> pd.Series:\n",
    "    return (series.astype(str)\n",
    "                  .str.strip()\n",
    "                  .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "                  .str.title())\n",
    "\n",
    "# --- Load original neighborhood resources ---\n",
    "df_orig = pd.read_csv(orig_path, dtype=str, engine=\"python\")\n",
    "df_orig.columns = df_orig.columns.str.strip()\n",
    "\n",
    "hood_col_orig = next((c for c in df_orig.columns if c.lower() == \"neighborhood\"), None)\n",
    "if hood_col_orig is None:\n",
    "    raise KeyError(\"Could not find a 'neighborhood' column in the original file.\")\n",
    "if hood_col_orig != \"neighborhood\":\n",
    "    df_orig = df_orig.rename(columns={hood_col_orig: \"neighborhood\"})\n",
    "\n",
    "df_orig[\"neighborhood\"] = normalize_hood(df_orig[\"neighborhood\"])\n",
    "\n",
    "# --- Load IRP file and count rows per neighborhood -> homeless_camps ---\n",
    "df_irp = pd.read_csv(irp_path, dtype=str, engine=\"python\")\n",
    "df_irp.columns = df_irp.columns.str.strip()\n",
    "\n",
    "candidates = [c for c in df_irp.columns if c.lower() in {\"neighborhood\", \"name\", \"neighborhood_name\", \"hood\"}]\n",
    "if not candidates:\n",
    "    raise KeyError(\"Could not locate a neighborhood column in the IRP file.\")\n",
    "hood_col_irp = next((c for c in candidates if c.lower() == \"neighborhood\"), candidates[0])\n",
    "\n",
    "df_irp[\"_neighborhood\"] = normalize_hood(df_irp[hood_col_irp])\n",
    "df_irp = df_irp.dropna(subset=[\"_neighborhood\"])\n",
    "\n",
    "homeless_counts = (\n",
    "    df_irp.groupby(\"_neighborhood\").size().rename(\"homeless_camps\").reset_index()\n",
    "          .rename(columns={\"_neighborhood\": \"neighborhood\"})\n",
    ")\n",
    "\n",
    "# --- Merge: include neighborhoods present in either file ---\n",
    "df_merged = pd.merge(df_orig, homeless_counts, on=\"neighborhood\", how=\"outer\")\n",
    "\n",
    "# Coerce all non-neighborhood columns to numeric ints (fill missing with 0)\n",
    "for col in df_merged.columns:\n",
    "    if col != \"neighborhood\":\n",
    "        df_merged[col] = pd.to_numeric(df_merged[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Save\n",
    "df_merged.to_csv(out_path, index=False)\n",
    "print(f\"Saved with homeless_camps added: {out_path}\")\n",
    "\n",
    "# Optional peek\n",
    "print(df_merged.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d825e420-2c64-4679-ac45-d3665732f133",
   "metadata": {},
   "source": [
    "Prompt: I see that there is at least one null in the neighborhoods field.  How would I remove records with a null neighborhood?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b7979-a36c-47b2-8ccf-00ec486de257",
   "metadata": {},
   "source": [
    "Each record in this file is a portland neighborhood and the number of homeless camps reported in 2024 as homeless_camps. Number_of_locations is the count of homeless resource providers in that neighborhood. final_resource_calc is the sum of all the resources available in that neighborhood, which is the rest of the fields except for the two I just described and the first one which is \"neighborhood\". What interesting statistics, charts and graphs would you suggest for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f8e6317-2fc0-43f8-95ba-fb11a7df9b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with homeless_camps and no null neighborhood records: C:\\Users\\Steph\\local\\OIT-class\\project-files\\datasets\\processed\\resources_by_hood_with_homeless_camps-csv.csv\n"
     ]
    }
   ],
   "source": [
    "# drop records with null neighborhoods\n",
    "df_nonulls = df_merged.dropna(subset=[\"neighborhood\"]).copy()\n",
    "\n",
    "# Save\n",
    "df_nonulls.to_csv(out_path, index=False)\n",
    "print(f\"Saved with homeless_camps and no null neighborhood records: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3eddee-46f7-44b5-aa52-d6f149e76c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following the output from ChatGPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"libraries imported!\")\n",
    "\n",
    "# ---------- Load & prep ----------\n",
    "# df = pd.read_csv(\"resources_by_hood_with_homeless_camps.csv\")\n",
    "df = df_merged.copy()\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Ensure numeric\n",
    "for c in [\"homeless_camps\",\"number_of_locations\",\"final_resource_calc\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Derived metrics\n",
    "df[\"camps_per_location\"]      = df[\"homeless_camps\"] / df[\"number_of_locations\"].replace(0, np.nan)\n",
    "df[\"resources_per_location\"]  = df[\"final_resource_calc\"] / df[\"number_of_locations\"].replace(0, np.nan)\n",
    "df[\"resources_per_camp\"]      = df[\"final_resource_calc\"] / df[\"homeless_camps\"].replace(0, np.nan)\n",
    "\n",
    "# ---------- 1) Summary stats ----------\n",
    "summary = {\n",
    "    \"total_homeless_camps\": int(df[\"homeless_camps\"].sum()),\n",
    "    \"total_locations\": int(df[\"number_of_locations\"].sum()),\n",
    "    \"total_resources\": int(df[\"final_resource_calc\"].sum()),\n",
    "    \"median_camps_per_location\": float(df[\"camps_per_location\"].median(skipna=True)),\n",
    "    \"median_resources_per_location\": float(df[\"resources_per_location\"].median(skipna=True)),\n",
    "    \"median_resources_per_camp\": float(df[\"resources_per_camp\"].median(skipna=True)),\n",
    "}\n",
    "print(summary)\n",
    "\n",
    "# ---------- 2) Top/Bottom bar charts ----------\n",
    "def plot_sorted_bar(series, title, xlabel):\n",
    "    s = series.sort_values(ascending=False)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(s.index, s.values)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Homeless camps by neighborhood.\")\n",
    "plot_sorted_bar(df.set_index(\"neighborhood\")[\"homeless_camps\"], \"Homeless camps by neighborhood\", \"Count\")\n",
    "print(\"Total resources by neighborhood.\")\n",
    "plot_sorted_bar(df.set_index(\"neighborhood\")[\"final_resource_calc\"], \"Total resources by neighborhood\", \"Count\")\n",
    "\n",
    "# ---------- 3) Scatter: camps vs resources (+ fit) ----------\n",
    "x = df[\"homeless_camps\"].values\n",
    "y = df[\"final_resource_calc\"].values\n",
    "mask = ~(np.isnan(x) | np.isnan(y))\n",
    "xv, yv = x[mask], y[mask]\n",
    "\n",
    "# Fit line\n",
    "if len(xv) >= 2:\n",
    "    m, b = np.polyfit(xv, yv, 1)\n",
    "    r = np.corrcoef(xv, yv)[0,1]\n",
    "else:\n",
    "    m, b, r = 0, 0, np.nan\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df[\"homeless_camps\"], df[\"final_resource_calc\"])\n",
    "if not np.isnan(r):\n",
    "    xs = np.linspace(df[\"homeless_camps\"].min(), df[\"homeless_camps\"].max(), 100)\n",
    "    plt.plot(xs, m*xs + b)\n",
    "    plt.title(f\"Resources vs Camps (Pearson r={r:.2f})\")\n",
    "else:\n",
    "    plt.title(\"Resources vs Camps\")\n",
    "plt.xlabel(\"Homeless camps\")\n",
    "plt.ylabel(\"Total resources\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Outliers by residual\n",
    "if not np.isnan(r):\n",
    "    df[\"residual\"] = df[\"final_resource_calc\"] - (m*df[\"homeless_camps\"] + b)\n",
    "    out_high_need_low_res = df.nsmallest(5, \"residual\")[[\"neighborhood\",\"homeless_camps\",\"final_resource_calc\",\"residual\"]]\n",
    "    out_low_need_high_res = df.nlargest(5, \"residual\")[[\"neighborhood\",\"homeless_camps\",\"final_resource_calc\",\"residual\"]]\n",
    "    print(\"\\nHigh need / low resources (most negative residuals):\\n\", out_high_need_low_res)\n",
    "    print(\"\\nLow need / high resources (most positive residuals):\\n\", out_low_need_high_res)\n",
    "\n",
    "# ---------- 4) Pareto curve & Gini ----------\n",
    "def pareto_and_gini(series, title):\n",
    "    s = series.sort_values(ascending=False).values\n",
    "    cum = np.cumsum(s)\n",
    "    cum_share = cum / cum[-1] if cum[-1] > 0 else cum\n",
    "    x = np.arange(1, len(s)+1) / len(s)\n",
    "    # Pareto plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(x, cum_share)\n",
    "    plt.plot([0,1],[0,1])  # equality line\n",
    "    plt.title(f\"Pareto: {title}\")\n",
    "    plt.xlabel(\"Share of neighborhoods\")\n",
    "    plt.ylabel(\"Cumulative share\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Gini\n",
    "    # Gini = 1 - 2 * area under Lorenz curve\n",
    "    lorenz = np.insert(np.cumsum(np.sort(series.values)), 0, 0)\n",
    "    lorenz = lorenz / lorenz[-1] if lorenz[-1] > 0 else lorenz\n",
    "    x2 = np.linspace(0, 1, len(lorenz))\n",
    "    gini = 1 - 2 * np.trapz(lorenz, x2)\n",
    "    print(f\"Gini for {title}: {gini:.3f}\")\n",
    "\n",
    "pareto_and_gini(df.set_index(\"neighborhood\")[\"homeless_camps\"], \"Homeless camps\")\n",
    "pareto_and_gini(df.set_index(\"neighborhood\")[\"final_resource_calc\"], \"Resources\")\n",
    "\n",
    "# ---------- 5) Quadrant chart (medians) ----------\n",
    "med_camps = df[\"homeless_camps\"].median()\n",
    "med_resources = df[\"final_resource_calc\"].median()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df[\"homeless_camps\"], df[\"final_resource_calc\"])\n",
    "plt.axvline(med_camps)\n",
    "plt.axhline(med_resources)\n",
    "plt.title(\"Quadrants: Need vs Resources (medians)\")\n",
    "plt.xlabel(\"Homeless camps (need)\")\n",
    "plt.ylabel(\"Total resources\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional labels for extreme points\n",
    "top = df.nlargest(5, \"homeless_camps\")\n",
    "for _, r_ in top.iterrows():\n",
    "    plt.text(r_[\"homeless_camps\"], r_[\"final_resource_calc\"], r_[\"neighborhood\"])\n",
    "\n",
    "# ---------- 6) Rates distributions ----------\n",
    "def plot_hist(series, title, xlabel):\n",
    "    vals = series.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.hist(vals, bins=15)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(df[\"resources_per_location\"], \"Resources per location\", \"resources/location\")\n",
    "plot_hist(df[\"resources_per_camp\"], \"Resources per camp\", \"resources/camp\")\n",
    "plot_hist(df[\"camps_per_location\"], \"Camps per location\", \"camps/location\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f56b9-de0e-489d-849b-a95a3cac44a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
